{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeatdstU96zN"
      },
      "source": [
        "# EuroSAT Training Pipeline (PyTorch)\n",
        "This notebook trains a ResNet50 on EuroSAT data and generates a CSV for test predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkddm1zb-Cw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34AoXx2l96zO"
      },
      "outputs": [],
      "source": [
        "# Install rasterio\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kjuNbuR96zP"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import rasterio\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS0H50hg96zP"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hht-Xi996zP"
      },
      "outputs": [],
      "source": [
        "# Set paths\n",
        "DATA_DIR = '/content/drive/MyDrive/eurosat'  # Place your EuroSAT data here\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "TEST_DIR = os.path.join(DATA_DIR, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzUUWSl296zQ"
      },
      "outputs": [],
      "source": [
        "# Dataset class for training (no cache, direct band slicing)\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, train_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.labels = []\n",
        "        for class_idx, class_name in enumerate(sorted(os.listdir(train_dir))):\n",
        "            class_path = os.path.join(train_dir, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                for f in os.listdir(class_path):\n",
        "                    if f.endswith('.tif'):\n",
        "                        img_path = os.path.join(class_path, f)\n",
        "                        self.samples.append(img_path)\n",
        "                        self.labels.append(class_idx)\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.samples[index]\n",
        "        with rasterio.open(img_path) as src:\n",
        "            img = src.read()  # shape: (bands, H, W)\n",
        "            img = np.transpose(img, (1, 2, 0))  # (H, W, bands)\n",
        "            image_rgb = img[:, :, [3,2,1]]\n",
        "            image_rgb = np.clip(image_rgb, 0, 255).astype(np.uint8)\n",
        "        pil_img = Image.fromarray(image_rgb)\n",
        "        if self.transform:\n",
        "            pil_img = self.transform(pil_img)\n",
        "        label = self.labels[index]\n",
        "        return pil_img, label\n",
        "    def __len__(self):\n",
        "        return len(self.samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tDLomiQ96zQ"
      },
      "outputs": [],
      "source": [
        "# Dataset class for test .npy files (nice id extraction)\n",
        "class TestNPYDataset(Dataset):\n",
        "    def __init__(self, test_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.ids = []\n",
        "        import re\n",
        "        def extract_num(filename):\n",
        "            match = re.search(r'test_(\\d+)\\.npy', filename)\n",
        "            return int(match.group(1)) if match else float('inf')\n",
        "        files = [f for f in os.listdir(test_dir) if f.endswith(\".npy\")]\n",
        "        for f in sorted(files, key=extract_num):\n",
        "            img_path = os.path.join(test_dir, f)\n",
        "            self.samples.append(img_path)\n",
        "            match = re.search(r'test_(\\d+)\\.npy', f)\n",
        "            self.ids.append(match.group(1) if match else f)\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.samples[index]\n",
        "        img_id = self.ids[index]\n",
        "        img = np.load(img_path)\n",
        "        image_rgb = img[:, :, [3,2,1]]\n",
        "        pil_img = Image.fromarray(image_rgb.astype(np.uint8))\n",
        "        if self.transform:\n",
        "            pil_img = self.transform(pil_img)\n",
        "        return pil_img, img_id\n",
        "    def __len__(self):\n",
        "        return len(self.samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4s3Tdkt96zQ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters and transforms\n",
        "class_names = [\n",
        "    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial',\n",
        "    'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'\n",
        "]\n",
        "input_size = 224\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.CenterCrop(input_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.CenterCrop(input_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG_Aei-i96zQ"
      },
      "outputs": [],
      "source": [
        "# Prepare dataset and loaders\n",
        "dataset = TrainDataset(TRAIN_DIR, transform=train_transform)\n",
        "val_size = int(0.2 * len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrzAXBhq96zR"
      },
      "outputs": [],
      "source": [
        "# Model setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from collections import Counter\n",
        "class_counts = Counter([label for label in dataset.labels])\n",
        "weights = torch.tensor([1.0 / class_counts[i] if class_counts[i] > 0 else 0.0 for i in range(len(class_names))], dtype=torch.float)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtrWZpCY96zR"
      },
      "outputs": [],
      "source": [
        "# Training loop with tqdm progress bar and checkpoints\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "    avg_loss = running_loss / len(train_loader.dataset)\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    val_acc = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Val Acc: {val_acc:.4f}')\n",
        "    # Per-class accuracy\n",
        "    class_correct = [0] * len(class_names)\n",
        "    class_total = [0] * len(class_names)\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                pred = preds[i].item()\n",
        "                if label == pred:\n",
        "                    class_correct[label] += 1\n",
        "                class_total[label] += 1\n",
        "    for i, cname in enumerate(class_names):\n",
        "        acc = class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "        print(f\"Val Acc {cname}: {acc:.4f}\")\n",
        "    # Save checkpoint\n",
        "    torch.save(model.state_dict(), f'eurosat_resnet50_epoch_{epoch+1}.pth')\n",
        "    print(f'Checkpoint saved: eurosat_resnet50_epoch_{epoch+1}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9H5nE5B96zR"
      },
      "outputs": [],
      "source": [
        "# Save final model weights\n",
        "torch.save(model.state_dict(), 'eurosat_resnet50.pth')\n",
        "print('Model trained and saved as eurosat_resnet50.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJShgnQT96zR"
      },
      "outputs": [],
      "source": [
        "# Test inference and CSV export\n",
        "test_dataset = TestNPYDataset(TEST_DIR, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "model.load_state_dict(torch.load('eurosat_resnet50.pth', map_location=device))\n",
        "model.eval()\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for img, img_id in tqdm(test_loader, desc='Testing'):\n",
        "        img = img.to(device)\n",
        "        outputs = model(img)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        label = class_names[pred.item()]\n",
        "        results.append({'test_id': img_id[0], 'label': label})\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('test_predictions.csv', index=False)\n",
        "print('test_predictions.csv saved.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}